---
title: Intro to Runes
sidebar_label: Intro to Runes
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Rune is a containerization technology for deploying TinyML applications to extremely constraint devices.

This will be a walkthrough on creating a rune to predict which gesture is being made by a device (using the devices accelerometer).

## Dependencies

The `rune` tool turns a Runefile into Rust code which is compiled to WebAssembly, so you will need to have the [**rust compiler**](https://rustup.rs/) installed.

We use the nightly compiler as it has some features which have not yet been added to the stable rust version.

```console
$ rustup toolchain install nightly
```

If you already have nightly installed, make sure you are running the latest version.

```console
$ rustup update nightly
```

Set nightly as your default.

```console
$ rustup default nightly
```

Compiling to WebAssembly requires copies of Rust's core libraries cross-compiled to `wasm32-unknown-unknown`.

```console
$ rustup target add wasm32-unknown-unknown
```

## Installation

Runes can be built and run using our `rune` command-line tool. There are 2 ways to set this up on your device.

### Cargo Install

Extremely simple cargo command to install the command-line tool.

```console
$ cargo install --git https://github.com/hotg-ai/rune rune
```

:::note
It might take a long time to download and compile the rune command-line tool.
:::

### Nightly Release

Alternatively, you can download our pre-compiled binaries from Github Releases under the [Nightly Release](https://github.com/hotg-ai/rune/releases/tag/nightly).

Install the `rune.x86_64- .zip` which matches your operating system. The file can be extracted in your location of choice.

There are a few additional steps we need to take to be able to use the command-line tool. Begin by entering the `rune.x86_64- ` directory.

<Tabs
  groupId="operating-systems"
  defaultValue="mac"
  values={[
    {label: 'macOS', value: 'mac'},
    {label: 'Linux', value: 'linux'},
  ]
}>
  <TabItem value="mac"><pre><code>$ cd rune.x86_64-apple-darwin</code></pre></TabItem>
  <TabItem value="linux"><pre><code>$ cd rune.x86_64-unknown-linux-gnu</code></pre></TabItem>
</Tabs> <br />

The `rune` binary is not yet a binary, it is a simple text file. We need to convert this into a Unix executable.

```console
$ chmod +x rune
```

Now we need to move the `rune` binary to where the other rust binaries are located.

```console
$ mv rune ~/.cargo/bin/
```

## Creating a Project

### Setup

The first step is to clone the [rune directory](https://github.com/hotg-ai/rune).

We will begin by creating a `Runefile` in the folder under `rune/docs/tutorial_gesture` with the following commands. Make sure you are in the cloned repo before running the commands.

1. `cd docs`
2. `cd tutorial_gesture`
3. `touch Runefile`

*Note: The Runefiles for other things like microspeech and person detection can be found in the `examples` directory*

### Runefile

The following is a basic template of a Runefile. Please read [What's In a Rune](https://Tinyverse.substack.com/p/whats-in-a-rune) to understand the different Directives that the Runfile has before completing the next step.

```rust
FROM runicos/base

DIRECTIVE<{Input}> {label_1} {TYPE} {optional_parameter}

DIRECTIVE<{Input},{Output}> {label_2} {file_location}

OUT serial

RUN {label_1} {label_2} serial
```

There are 3 Directives that can be called. The data input and output needs to be specified as follows.

1. `CAPABILITY` (Input Only)
2. `MODEL` (Input and Output)
3. `PROC_BLOCK` (Input and Output)

Each of these has an `{Input}` and `{Output}` which follow the following format:
      `{Data Type}[array]` i.e. `f32[128, 3]`

The next step in the creation of the Runefile is to name each of the directives by changing `{label_#}`. The label of each stage will be used to execute them in the final `RUN` directive.

The `CAPABILITY` directive processes the initial data according to what is required. We currently support

- RAND (generates buffer with random data)
- SOUND (consumes sound)
- ACCEL (consumes x, y, z data from the accelerometer)
- IMAGE (consumes an image of x, y )

The `PROC_BLOCK` directive allows for pre- and post-processing of the data. For example, if the model needs the data to be normalized to values between 0 and 1, you can create a `PROC_BLOCK` to perform this pre processing.

```rust
PROC_BLOCK<f32[128, 3],f32[128, 3]> normalize hotg-ai/rune#proc_blocks/normalize
```

The input and output of the Processing Block are the same `f32[128, 3]`. The label for the Processing block is `normalize` and the location of the Processing Block is `hotg-ai/rune#proc_blocks/normalize`.

The `MODEL` directive tells the rune to use the tflite model.

The `OUT` directive sends the data to be consumed by the host  device. serial output sends the data as JSON.

Populate the Runefile with the following:

```rust title="Runefile"
FROM runicos/base

CAPABILITY<f32[128, 3]> accelerometer ACCEL -n 128

PROC_BLOCK<f32[128, 3],f32[128, 3]> normalize hotg-ai/rune#proc_blocks/normalize

MODEL<f32[128, 3],f32[4]> gesture ./model.tflite

PROC_BLOCK<f32[64], UTF8> gesture_agg hotg-ai/rune#proc_blocks/gesture_agg --labels=Wing,Ring,Slope,Unknown

OUT SERIAL

RUN accelerometer normalize gesture gesture_agg serial
```

CAPABILITY will process incoming data into a floating point `128 * 3` array.

The normalize PROC_BLOCK is used to compress the incoming data between 0 and 1.

The data is then run through the tflite MODEL producing an output of 4 floating point numbers with different levels of confidence of the model (i.e. `[0.0, 1.0, 0.0, 0.0]`).

The gesture_agg PROC_BLOCK takes the ouptut of the model, and returns a UTF8 from the labels provided (`--labels=Wing, Ring, Slope, Unknown`)
(example output based on previous model output: `Ring`).

The UTF8 label is then sent to the serial which can be read by whichever device the rune is being deployed to.

### Processing Blocks

The necessary PROC_BLOCKS to be used in `tutorial_gesture` have already been created and are stored in `proc_blocks/`

Further Tutorials shall explain how to create your own processing block.

### Model

Trained tflite models should be placed in the same directory as the `Runefile` (because the `Runefile` is expecting the model to be located in `./model.tflite`). A different location can be used but the MODEL line in the `Runefile` will need to be updated to point to the changed location.

For convenience `docs/tutorial_gesture` already contains the tflite model we will be using for this tutorial.

### Build

Great! Now that everything is setup, we can generate the rune :)

1. Open terminal and go to the `rune` directory. Run the next command.
2. `cargo run --bin rune -- build docs/tutorial_gesture/Runefile`

Your rune `tutorial_gesture.rune` will be generated in the same directory as the `Runefile`.

Congrats! You now have a rune which can be deployed on your devices.

### Testing

You can run the Rune with test data which has been provided in the `docs/tutorial_gesture` directory using the following command.

>```cargo run --bin rune -- run docs/tutorial_gesture/tutorial_gesture.rune --capability accelerometer:docs/tutorial_gesture/example_ring.csv```

`example_ring.csv` contains data similar to what an accelerometer would collect if a ring gesture was made.

The Serial output of running the above command should be `Ring`.
